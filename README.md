#  LiveKit LLM Voice Agent

This project demonstrates real-time audio streaming, intelligent LLM-based response generation, interruption handling, and modular production architecture using Python.

---

#  Features

- Real-time audio streaming via LiveKit (WebRTC)
- Voice Activity Detection (WebRTC VAD)
- Streaming Speech-to-Text (Google Cloud)
- LLM-powered contextual responses (OpenAI GPT)
- Text-to-Speech synthesis (Google Cloud)
- Conversation memory (short-term context retention)
- Interruption handling (user can stop bot mid-response)
- Silence detection with reminder prompt
- Docker-ready deployment

---

#  Architecture Overview

User Speech  
‚Üí LiveKit Audio Track  
‚Üí Voice Activity Detection (VAD)  
‚Üí Google Speech-to-Text  
‚Üí OpenAI GPT (LLM)  
‚Üí Google Text-to-Speech  
‚Üí LiveKit Audio Output  

---

# Setup Instructions

## 1Ô∏è‚É£ Clone the Repository

```bash
git clone https://github.com/your-username/livekit-llm-voice-agent.git
cd livekit-llm-voice-agent

## 2Ô∏è‚É£ Create Virtual Environment (Recommended)
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

## 3Ô∏è‚É£ Install Dependencies
pip install -r requirements.txt

##4Ô∏è‚É£ Configure Environment Variables
Create a .env file in the root directory.
Use .env.example as reference.

## Required Environment Variables

Create a .env file with the following:

LIVEKIT_URL=
LIVEKIT_API_KEY=
LIVEKIT_API_SECRET=

OPENAI_API_KEY=

GOOGLE_APPLICATION_CREDENTIALS=/absolute/path/to/gcloud.json

##‚ñ∂Ô∏è How to Run

After setting environment variables:

python app/main.py

The bot will:

Connect to LiveKit room

Listen to user speech

Convert speech to text

Generate intelligent response using GPT

Convert response to speech

Play audio back into the room

##  Run with Docker (Optional)
docker build -t voice-agent .
docker run --env-file .env voice-agent

##üì¶ SDKs & Libraries Used
Core SDKs

LiveKit Python SDK ‚Äì Real-time WebRTC audio streaming

OpenAI Python SDK ‚Äì GPT LLM integration

Google Cloud Speech SDK ‚Äì Streaming Speech-to-Text

Google Cloud Text-to-Speech SDK ‚Äì Audio response synthesis

WebRTC VAD (webrtcvad) ‚Äì Voice activity detection

Supporting Libraries

numpy

structlog

python-dotenv

asyncio

##  External Services Used

This project depends on the following external services:

LiveKit Server

Handles real-time WebRTC communication

OpenAI API

Generates intelligent conversational responses

Google Cloud Speech-to-Text

Converts speech audio to text

Google Cloud Text-to-Speech

Converts LLM response text into audio

These services require valid API credentials.

##  Known Limitations

Short-term memory only (last ~10 conversation turns)

No persistent database storage

Single-room / single-session oriented

Not optimized for ultra-low latency streaming yet

No authentication layer for participants

No horizontal scaling configuration (requires Kubernetes for production scale)

Basic silence detection (not ML-based endpoint detection)

## Future Improvements

Redis-backed conversation memory

RAG (Retrieval Augmented Generation)

Streaming LLM response playback

Multi-user room support

Prometheus metrics & observability

Kubernetes deployment

Speaker diarization

Emotion-aware conversational prompting